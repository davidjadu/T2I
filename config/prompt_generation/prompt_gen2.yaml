experiment:
  name: "color+size"

prompt_generation:
  metadata_config:
    name: "coco"
  skills:
    - level: "easy"
      skills: ["counting", "color", "spatial", "emotion", "size"]
      robustness: ["typos"]
      k: 4
    - level: "hard"
      skills: ["emotion", "text"]
      k: 7
  llm_model:
    name: "ollama"
    model: "llama3.2:latest"
    host: "localhost"
    port: 11434
    temperature: 0.7
  samples_per_skill: 4

output:
  file: "outputs/prompts/color+size_2.json"
