{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "667343bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13921e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('size+emotion+text_robust.json', True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = \"size+emotion+text_robust.json\"\n",
    "robust = \"robust\" in A\n",
    "A, robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e8de679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'size+emotion+text'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = A[:-12] if robust else A[-5]\n",
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9199c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=\"color+text\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8780f",
   "metadata": {},
   "source": [
    "# JSON load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5c3669bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../outputs/prompts'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_dir = Path(\"../../outputs/prompts\")\n",
    "json_files = [p for p in json_dir.glob(\"*\") if p.is_file()]\n",
    "basedir_name = \"../../data/images_refactored/animagine\"\n",
    "files = Path(\"../../data/images_refactored/animagine\")\n",
    "output_files = [p for p in files.glob(\"*\") if p.is_file()]\n",
    "os.path.commonpath(json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f82b3339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../../data/images_refactored/animagine/color+spatial+text.json')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(basedir_name + f\"/{os.path.basename(json_files[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d60439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = dict()\n",
    "with open(\"../../outputs/prompts/color+size.json\", \"rb\") as file:\n",
    "    elements = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c55dad63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard A scene shows a large blue truck towering over a smaller brown motorcycle, while a compact purple laptop, noticeably smaller than a nearby black cell phone, rests on a table in the foreground.\n",
      "Output file name: dalle_10_hard_001_0 \n",
      "hard A wide-angle urban scene in daylight: several large blue trucks tower over and are visibly larger than the smaller brown motorcycles parked along the curb; in the foreground a compact purple laptop, deliberately tiny, sits on a bench and is clearly smaller than a nearby black cell phone resting beside it.\n",
      "Output file name: dalle_10_hard_001_1 \n",
      "hard A scene featuring a large blue truck parked next to a smaller brown motorcycle, and nearby a small purple laptop sitting on a table that is clearly smaller than a black cell phone placed beside it.\n",
      "Output file name: dalle_10_hard_001_2 \n",
      "hard A street scene shows a large blue truck dominating the foreground beside a smaller brown motorcycle, while a sleek black cell phone rests next to a compact purple laptop that is noticeably smaller than the phone.\n",
      "Output file name: dalle_10_hard_001_3 \n",
      "hard A street-side scene showing a tiny purple laptop sitting on a bench, noticeably smaller than a nearby black cell phone that lies beside it; in the roadway a large blue truck dominates the view and dwarfs several brown motorcycles clustered in front of it, with natural daylight and realistic textures.\n",
      "Output file name: dalle_10_hard_001_4 \n",
      "medium A bright staged still life showing a compact blue microwave placed on a mid-height shelf, a tall purple umbrella leaning against a wall behind it, and a short pink surfboard propped on the floor; the blue microwave is visibly smaller than the purple umbrella but noticeably larger than the pink surfboard.\n",
      "Output file name: dalle_10_medium_001_0 \n",
      "medium A surreal beach scene featuring a large purple umbrella towering overhead, a medium-sized blue microwave sitting on the sand beneath it, and a small pink surfboard resting nearby, with the umbrella clearly the largest object and the surfboard the smallest.\n",
      "Output file name: dalle_10_medium_001_1 \n",
      "medium An outdoor beach scene centered on a tall purple umbrella shading a medium blue microwave on a wooden table; the blue microwave is noticeably smaller than the umbrella yet clearly larger than two compact pink surfboards leaning against the table, with soft sand and gentle waves in the background.\n",
      "Output file name: dalle_10_medium_001_2 \n",
      "easy A bright, sunlit scene showing a large yellow truck dominating the foreground and a small pink backpack resting on the curb nearby, the truck clearly much larger than the backpack, vivid colors and crisp details.\n",
      "Output file name: dalle_10_easy_001_0 \n",
      "easy A sunlit urban scene showing a large yellow truck dominating the foreground, its glossy body and oversized wheels clearly much larger than a small pink backpack left on the sidewalk beside the curb; realistic photographic style, soft shadows, scattered leaves, and shallow depth of field emphasizing the size difference.\n",
      "Output file name: dalle_10_easy_001_1 \n"
     ]
    }
   ],
   "source": [
    "for prompt in elements[\"prompts\"]:\n",
    "    # Get the id \n",
    "    prompt_number = prompt[\"id\"].split(\"_\")[1]\n",
    "    # Get the level \n",
    "    prompt_level = prompt[\"level\"]\n",
    "    # Get the synthetic prompts\n",
    "    synthetic_prompts = prompt[\"synthetic_prompts\"]\n",
    "    # Loop through the synthetic prompts\n",
    "    for i,gen_prompt in enumerate(synthetic_prompts):\n",
    "        # Display them \n",
    "        print(prompt_level,gen_prompt)\n",
    "        # Set the output file name\n",
    "        output_file_name = \"dalle\" + \"_\" + str(10) + \"_\" + prompt_level + \"_\" + str(prompt_number) + \"_\" + str(i)\n",
    "        print(f\"Output file name: {output_file_name} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06ffc355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "code_file = pd.read_csv(\"../../skills_code.csv\", encoding=\"utf-8\")\n",
    "code = code_file.loc[code_file[\"skill\"]==skills, \"code\"]\n",
    "\n",
    "if not code.empty: \n",
    "    code = code.iloc[0]\n",
    "else: \n",
    "    code = None\n",
    "\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19514d",
   "metadata": {},
   "source": [
    "# Looping through the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24a733f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 .yaml files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the base directory\n",
    "base_dir = Path(\"../../config/prompt_generation\")\n",
    "# Get the file names\n",
    "files = [p for p in base_dir.glob(\"*\") if p.is_file()]\n",
    "files.sort()\n",
    "print(f\"{len(files)} .yaml files.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0ba57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the dict\n",
    "skills_code = dict()\n",
    "# Loop through the files\n",
    "for i,file in enumerate(files):\n",
    "    # Retrieve the file name without extension\n",
    "    name = os.path.basename(file)[0:-5]\n",
    "    # Append to the dict\n",
    "    skills_code[i] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991c34f",
   "metadata": {},
   "source": [
    "# Save into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915b5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../skills_code.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"code\", \"skill\"])\n",
    "    for code, skill in skills_code.items():\n",
    "        writer.writerow([code,skill])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
