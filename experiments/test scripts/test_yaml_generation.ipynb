{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a57e1c",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd372d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import yaml\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0f77b",
   "metadata": {},
   "source": [
    "# Skills combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3040fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible combinations (2-skill):\n",
      "[('counting', 'color'), ('counting', 'spatial'), ('counting', 'size'), ('counting', 'emotion'), ('counting', 'text'), ('color', 'spatial'), ('color', 'size'), ('color', 'emotion'), ('color', 'text'), ('spatial', 'size'), ('spatial', 'emotion'), ('spatial', 'text'), ('size', 'emotion'), ('size', 'text'), ('emotion', 'text')]\n",
      "Possible combinations (3-skill):\n",
      "[('counting', 'color', 'spatial'), ('counting', 'color', 'size'), ('counting', 'color', 'emotion'), ('counting', 'color', 'text'), ('counting', 'spatial', 'size'), ('counting', 'spatial', 'emotion'), ('counting', 'spatial', 'text'), ('counting', 'size', 'emotion'), ('counting', 'size', 'text'), ('counting', 'emotion', 'text'), ('color', 'spatial', 'size'), ('color', 'spatial', 'emotion'), ('color', 'spatial', 'text'), ('color', 'size', 'emotion'), ('color', 'size', 'text'), ('color', 'emotion', 'text'), ('spatial', 'size', 'emotion'), ('spatial', 'size', 'text'), ('spatial', 'emotion', 'text'), ('size', 'emotion', 'text')]\n",
      "Possible combinations (4-skill):\n",
      "[('counting', 'color', 'spatial', 'size'), ('counting', 'color', 'spatial', 'emotion'), ('counting', 'color', 'spatial', 'text'), ('counting', 'color', 'size', 'emotion'), ('counting', 'color', 'size', 'text'), ('counting', 'color', 'emotion', 'text'), ('counting', 'spatial', 'size', 'emotion'), ('counting', 'spatial', 'size', 'text'), ('counting', 'spatial', 'emotion', 'text'), ('counting', 'size', 'emotion', 'text'), ('color', 'spatial', 'size', 'emotion'), ('color', 'spatial', 'size', 'text'), ('color', 'spatial', 'emotion', 'text'), ('color', 'size', 'emotion', 'text'), ('spatial', 'size', 'emotion', 'text')]\n",
      "Possible combinations (5-skill):\n",
      "[('counting', 'color', 'spatial', 'size', 'emotion'), ('counting', 'color', 'spatial', 'size', 'text'), ('counting', 'color', 'spatial', 'emotion', 'text'), ('counting', 'color', 'size', 'emotion', 'text'), ('counting', 'spatial', 'size', 'emotion', 'text'), ('color', 'spatial', 'size', 'emotion', 'text')]\n",
      "112 yaml files to generate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skills = [\"counting\", \"color\", \"spatial\", \"size\", \"emotion\", \"text\"]\n",
    "combinations_2 =  list(itertools.combinations(skills,2))\n",
    "combinations_3 = list(itertools.combinations(skills,3))\n",
    "combinations_4 = list(itertools.combinations(skills,4))\n",
    "combinations_5 =  list(itertools.combinations(skills,5))\n",
    "print(f\"Possible combinations (2-skill):\\n{combinations_2}\")\n",
    "print(f\"Possible combinations (3-skill):\\n{combinations_3}\")\n",
    "print(f\"Possible combinations (4-skill):\\n{combinations_4}\")\n",
    "print(f\"Possible combinations (5-skill):\\n{combinations_5}\")\n",
    "print(f\"{(len(combinations_2)+len(combinations_3)+len(combinations_4)+len(combinations_5))*2} yaml files to generate.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542a079",
   "metadata": {},
   "source": [
    "# Generate combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9769df5b",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55783189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InlineList(list):\n",
    "    pass\n",
    "\n",
    "def inline_list_representer(dumper, data):\n",
    "    return dumper.represent_sequence(\n",
    "        'tag:yaml.org,2002:seq', data, flow_style=True\n",
    "    )\n",
    "\n",
    "yaml.add_representer(InlineList, inline_list_representer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73a28f",
   "metadata": {},
   "source": [
    "## 2-skill combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed269c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the skills\n",
    "for s1,s2 in combinations_2:\n",
    "    # Generate the dict (normal)\n",
    "    yaml_dict = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2]), \n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2]), \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2]), \n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}.json\"\n",
    "        }\n",
    "    }\n",
    "    # Generate the dict (robust)\n",
    "    yaml_dict_robust = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}_robust\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),     \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}_robust.json\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create file if not exists (normal)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict, sort_keys=False, \n",
    "                         default_flow_style=False))\n",
    "    \n",
    "    # Create file if not exists (robust)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}_robust.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict_robust, sort_keys=False, \n",
    "                         default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd339b",
   "metadata": {},
   "source": [
    "## 3-skill combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64effd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the skills\n",
    "for s1,s2,s3 in combinations_3:\n",
    "    # Generate the dict (normal)\n",
    "    yaml_dict = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}+{s3}\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2,s3]), \n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2,s3]), \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2,s3]), \n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}+{s3}.json\"\n",
    "        }\n",
    "    }\n",
    "    # Generate the dict (robust)\n",
    "    yaml_dict_robust = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}+{s3}_robust\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2,s3]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2,s3]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),     \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2,s3]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}+{s3}_robust.json\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create file if not exists (normal)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}+{s3}.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict, sort_keys=False, \n",
    "                         default_flow_style=False))\n",
    "    \n",
    "    # Create file if not exists (robust)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}+{s3}_robust.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict_robust, sort_keys=False, \n",
    "                         default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276dab6",
   "metadata": {},
   "source": [
    "## 4-skill combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c50550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the skills\n",
    "for s1,s2,s3, s4 in combinations_4:\n",
    "    # Generate the dict (normal)\n",
    "    yaml_dict = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}+{s3}+{s4}\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4]), \n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4]), \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4]), \n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}+{s3}+{s4}.json\"\n",
    "        }\n",
    "    }\n",
    "    # Generate the dict (robust)\n",
    "    yaml_dict_robust = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}+{s3}+{s4}_robust\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),     \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}+{s3}+{s4}_robust.json\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create file if not exists (normal)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}+{s3}+{s4}.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict, sort_keys=False, \n",
    "                         default_flow_style=False))\n",
    "    \n",
    "    # Create file if not exists (robust)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}+{s3}+{s4}_robust.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict_robust, sort_keys=False, \n",
    "                         default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e678f29c",
   "metadata": {},
   "source": [
    "## 5-skill combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b942437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loop through the skills\n",
    "for s1,s2,s3,s4,s5 in combinations_5:\n",
    "    # Generate the dict (normal)\n",
    "    yaml_dict = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}+{s3}+{s4}+{s5}\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4,s5]), \n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4,s5]), \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4,s5]), \n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}+{s3}+{s4}+{s5}.json\"\n",
    "        }\n",
    "    }\n",
    "    # Generate the dict (robust)\n",
    "    yaml_dict_robust = {\n",
    "        \"experiment\": {\"name\": f\"{s1}+{s2}+{s3}+{s4}+{s5}_robust\"}, \n",
    "        \"prompt_generation\": \n",
    "        {\n",
    "            \"metadata_config\": {\n",
    "                \"name\": \"coco\"\n",
    "            }, \n",
    "            \"skills\": [\n",
    "                {\n",
    "                \"level\": \"hard\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4,s5]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 5\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"medium\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4,s5]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),     \n",
    "                \"k\": 3\n",
    "                }, \n",
    "                {\n",
    "                \"level\": \"easy\",\n",
    "                \"skills\": InlineList([s1,s2,s3,s4,s5]), \n",
    "                \"robustness\": InlineList([\"typos\", \"consistency\"]),\n",
    "                \"k\": 2\n",
    "                }\n",
    "            ], \n",
    "            \"llm_model\": \n",
    "            {\n",
    "                \"name\": \"openai\", \n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"temperature\": 1\n",
    "            }, \n",
    "            \"samples_per_skill\": 1\n",
    "        }, \n",
    "        \"output\": \n",
    "        {\n",
    "            \"file\": f\"outputs/prompts/{s1}+{s2}+{s3}+{s4}+{s5}_robust.json\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create file if not exists (normal)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}+{s3}+{s4}+{s5}.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict, sort_keys=False, \n",
    "                         default_flow_style=False))\n",
    "    \n",
    "    # Create file if not exists (robust)\n",
    "    with open(f\"../../config/prompt_generation/{s1}+{s2}+{s3}+{s4}+{s5}_robust.yaml\", \"w+\") as file:\n",
    "        # Write into the file (normal)\n",
    "        file.write(yaml.dump(yaml_dict_robust, sort_keys=False, \n",
    "                         default_flow_style=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
